\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Abstract}{i}{dummy.1}}
\@writefile{toc}{\vspace  {1em}}
\@writefile{toc}{\contentsline {chapter}{Contents}{ii}{dummy.2}}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{iv}{dummy.4}}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter 1}{{1}{1}{Introduction}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation and Aims}{1}{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Contributions}{2}{section.8}}
\citation{schmidhuber2014deep}
\citation{bengio2013advances}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{3}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter 2}{{2}{3}{Related Work}{chapter.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Overview}{3}{section.10}}
\citation{lytton2002hodgkin}
\citation{dahl2013improving}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Recurrent Neural Network}{4}{section.11}}
\citation{werbos1990backpropagation}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Recurrent Neural Network}}{5}{figure.caption.12}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rnn}{{2.1}{5}{Recurrent Neural Network}{figure.caption.12}{}}
\citation{dahl2013improving}
\citation{krizhevsky2012imagenet}
\citation{hochreiter1997long}
\citation{pascanu2012difficulty}
\citation{martens2010deep}
\citation{martens2011learning}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Hessian Free Optimization}{6}{section.13}}
\citation{martens2011learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Difficulty of gradient descent}}{7}{figure.caption.14}}
\newlabel{fig:gradient_elipse}{{2.2}{7}{Difficulty of gradient descent}{figure.caption.14}{}}
\citation{sutskever2011generating}
\citation{boulanger2012modeling}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Text and Polyphonic Music Generation using Recurrent Neural Networks}{8}{section.15}}
\citation{sutskever2008recurrent}
\citation{boulanger2012modeling}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces RTRBM Graphical Model}}{9}{figure.caption.16}}
\newlabel{fig:rtrbm}{{2.3}{9}{RTRBM Graphical Model}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces RNN-RBM Graphical Model}}{10}{figure.caption.17}}
\newlabel{fig:rtrbm}{{2.4}{10}{RNN-RBM Graphical Model}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Training Restricted Boltzman Machines unsing constrastive divergence.}{10}{section.18}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces CD calculaiton}}{11}{figure.caption.19}}
\newlabel{fig:calc_cd}{{2.5}{11}{CD calculaiton}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Gibbs sampling}}{11}{figure.caption.20}}
\newlabel{fig:gibbs_sampling}{{2.6}{11}{Gibbs sampling}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3} Study of the internal structure of a previously trained Recurrent Neural Network}{13}{chapter.21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter 3}{{3}{13}{Study of the internal structure of a previously trained Recurrent Neural Network}{chapter.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Motivation}{13}{section.22}}
\citation{boulanger2012modeling}
\citation{koren2003spectral}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Experiments}{14}{section.23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Problem}{14}{subsection.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Plot of the RNN}{14}{subsection.25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Plot of the RNN using weights as springs}}{16}{figure.caption.26}}
\newlabel{fig:ring_lattice}{{3.1}{16}{Plot of the RNN using weights as springs}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Plot of the RNN with spectral analyses of the Laplacian Matrix }}{16}{figure.caption.27}}
\newlabel{fig:ring_lattice}{{3.2}{16}{Plot of the RNN with spectral analyses of the Laplacian Matrix}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Weight distribution}{17}{subsection.28}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Weight distribution }}{17}{figure.caption.29}}
\newlabel{fig:weight_dist}{{3.3}{17}{Weight distribution}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Distribution of the absolute value of the weights}}{17}{figure.caption.30}}
\newlabel{fig:abs_weight_dist}{{3.4}{17}{Distribution of the absolute value of the weights}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Sums of weights}{17}{subsection.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Distribution of the sum of the input connection weights on Whh}}{18}{figure.caption.32}}
\newlabel{fig:input_sum}{{3.5}{18}{Distribution of the sum of the input connection weights on Whh}{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Distribution of the sum of the output connection weights on Whh}}{18}{figure.caption.33}}
\newlabel{fig:output_sum}{{3.6}{18}{Distribution of the sum of the output connection weights on Whh}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Removing neurons of the network.}{18}{subsection.34}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Error on the test set when removing 1 neuron}}{19}{figure.caption.35}}
\newlabel{fig:error_one_neuron}{{3.7}{19}{Error on the test set when removing 1 neuron}{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces M1}}{21}{figure.caption.36}}
\newlabel{fig:m1}{{3.8}{21}{M1}{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces M2}}{21}{figure.caption.37}}
\newlabel{fig:m2}{{3.9}{21}{M2}{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces M3}}{22}{figure.caption.38}}
\newlabel{fig:m3}{{3.10}{22}{M3}{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces M4}}{22}{figure.caption.39}}
\newlabel{fig:m4}{{3.11}{22}{M4}{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces M5}}{23}{figure.caption.40}}
\newlabel{fig:m5}{{3.12}{23}{M5}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces M6}}{23}{figure.caption.41}}
\newlabel{fig:m6}{{3.13}{23}{M6}{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces M7}}{24}{figure.caption.42}}
\newlabel{fig:m7}{{3.14}{24}{M7}{figure.caption.42}{}}
\newlabel{fig:metrics}{{\caption@xref {fig:metrics}{ on input line 230}}{24}{Removing neurons of the network}{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Table presenting the value of d for the different metrics }}{24}{figure.caption.43}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4} Self-Growing Recurrent Neural Network}{25}{chapter.44}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter 2}{{4}{25}{Self-Growing Recurrent Neural Network}{chapter.44}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{25}{section.45}}
\citation{martens2011learning}
\citation{boulanger2012modeling}
\citation{martens2011learning}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}SGRNN}{26}{section.46}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Learning algorithm\relax }}{26}{algorithm.47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Implementation of the Hessian Free Optimization step}{26}{subsection.56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Weights Initialization}{27}{subsection.57}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces A ring lattice}}{27}{figure.caption.58}}
\newlabel{fig:ring_lattice}{{4.1}{27}{A ring lattice}{figure.caption.58}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Evolution Step}{28}{subsection.59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Reordering Step}{28}{subsection.60}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion and Future Work}{29}{chapter.61}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter 5}{{5}{29}{Conclusion and Future Work}{chapter.61}{}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{toc}{\vspace  {2em}}
\bibstyle{unsrtnat}
\bibdata{Bibliography}
\bibcite{schmidhuber2014deep}{{1}{2014}{{Schmidhuber}}{{}}}
\bibcite{bengio2013advances}{{2}{2013}{{Bengio et~al.}}{{Bengio, Boulanger-Lewandowski, and Pascanu}}}
\bibcite{lytton2002hodgkin}{{3}{2002}{{Lytton}}{{}}}
\bibcite{dahl2013improving}{{4}{2013}{{Dahl et~al.}}{{Dahl, Sainath, and Hinton}}}
\bibcite{werbos1990backpropagation}{{5}{1990}{{Werbos}}{{}}}
\bibcite{krizhevsky2012imagenet}{{6}{2012}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, and Hinton}}}
\bibcite{hochreiter1997long}{{7}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{pascanu2012difficulty}{{8}{2012}{{Pascanu et~al.}}{{Pascanu, Mikolov, and Bengio}}}
\bibcite{martens2010deep}{{9}{2010}{{Martens}}{{}}}
\bibcite{martens2011learning}{{10}{2011}{{Martens and Sutskever}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{30}{dummy.62}}
\newlabel{Bibliography}{{4}{30}{Conclusion and Future Work}{dummy.62}{}}
\bibcite{sutskever2011generating}{{11}{2011}{{Sutskever et~al.}}{{Sutskever, Martens, and Hinton}}}
\bibcite{boulanger2012modeling}{{12}{2012}{{Boulanger-Lewandowski et~al.}}{{Boulanger-Lewandowski, Bengio, and Vincent}}}
\bibcite{sutskever2008recurrent}{{13}{2008}{{Sutskever et~al.}}{{Sutskever, Hinton, and Taylor}}}
\bibcite{koren2003spectral}{{14}{2003}{{Koren}}{{}}}
